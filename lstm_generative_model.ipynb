{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Use LSTM to generate the poem\n",
    "\n",
    "The procedure:\n",
    "\n",
    "1. Embedding Layer;\n",
    "2. LSTM Decoder-only;\n",
    "3. Sample for generation;\n",
    "4. Use all data to train, which overfits the training data."
   ],
   "id": "67d05df12625237f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:56:52.763687Z",
     "start_time": "2025-08-27T06:56:52.353206Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install pandas",
   "id": "5cd8e1b35e1257b7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\n",
      "Requirement already satisfied: pandas in /home/hello/miniconda3/envs/nlpia/lib/python3.12/site-packages (2.3.2)\r\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/hello/miniconda3/envs/nlpia/lib/python3.12/site-packages (from pandas) (2.1.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/hello/miniconda3/envs/nlpia/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/hello/miniconda3/envs/nlpia/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/hello/miniconda3/envs/nlpia/lib/python3.12/site-packages (from pandas) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/hello/miniconda3/envs/nlpia/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Download The Dataset",
   "id": "243f99368fd6af89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:56:52.874330Z",
     "start_time": "2025-08-27T06:56:52.858640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%%script echo skipping\n",
    "\n",
    "# Optional: set the proxy\n",
    "%env all_proxy=socks5://127.0.0.1:7897\n",
    "\n",
    "!mkdir -p data\n",
    "!git clone https://github.com/xiu-ze/Poetry.git data/Poetry"
   ],
   "id": "71814b0fc679536",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:56:52.988629Z",
     "start_time": "2025-08-27T06:56:52.972539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get all files\n",
    "import os\n",
    "\n",
    "def get_all_files(base_dir):\n",
    "    all_files = []\n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        for file in files:\n",
    "            all_files.append(os.path.join(root, file))\n",
    "    return all_files\n",
    "\n",
    "base_dir = os.path.expanduser('data/Poetry/诗歌数据集')\n",
    "poem_files = get_all_files(base_dir)\n",
    "poem_files"
   ],
   "id": "8488e291bbcafca6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/Poetry/诗歌数据集/秦.csv',\n",
       " 'data/Poetry/诗歌数据集/先秦.csv',\n",
       " 'data/Poetry/诗歌数据集/隋.csv',\n",
       " 'data/Poetry/诗歌数据集/辽.csv',\n",
       " 'data/Poetry/诗歌数据集/当代.csv',\n",
       " 'data/Poetry/诗歌数据集/明_1.csv',\n",
       " 'data/Poetry/诗歌数据集/明_2.csv',\n",
       " 'data/Poetry/诗歌数据集/明_3.csv',\n",
       " 'data/Poetry/诗歌数据集/清_3.csv',\n",
       " 'data/Poetry/诗歌数据集/清_2.csv',\n",
       " 'data/Poetry/诗歌数据集/明_4.csv',\n",
       " 'data/Poetry/诗歌数据集/元.csv',\n",
       " 'data/Poetry/诗歌数据集/清_1.csv',\n",
       " 'data/Poetry/诗歌数据集/南北朝.csv',\n",
       " 'data/Poetry/诗歌数据集/宋_1.csv',\n",
       " 'data/Poetry/诗歌数据集/宋_2.csv',\n",
       " 'data/Poetry/诗歌数据集/唐.csv',\n",
       " 'data/Poetry/诗歌数据集/近现代.csv',\n",
       " 'data/Poetry/诗歌数据集/宋_3.csv',\n",
       " 'data/Poetry/诗歌数据集/汉.csv',\n",
       " 'data/Poetry/诗歌数据集/金.csv',\n",
       " 'data/Poetry/诗歌数据集/魏晋.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Clean the dataset\n",
    "\n",
    "1. Truncate the poems to 24 characters;\n",
    "2. Check the invalid signs in the fixed positions and remove the abnormal items."
   ],
   "id": "67716901997dc298"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:56:53.268157Z",
     "start_time": "2025-08-27T06:56:53.092765Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read dataset from one file\n",
    "import pandas as pd\n",
    "\n",
    "project_root = os.path.abspath('.')\n",
    "\n",
    "def read_file_to_df(file_path):\n",
    "    file = os.path.join(project_root, file_path)\n",
    "    if not os.path.exists(file):\n",
    "        raise FileNotFoundError(f\"File {file} does not exist.\")\n",
    "\n",
    "    df = pd.read_csv(file)\n",
    "    filter_by_wujue = df[df[\"体裁\"].astype(str).str.contains(\"五言绝句\", na=False)].copy()\n",
    "    wujue_content = filter_by_wujue['内容']\n",
    "    return wujue_content"
   ],
   "id": "46885637a1419f00",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:56:53.312317Z",
     "start_time": "2025-08-27T06:56:53.305932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transform the pandas Series to numpy array and check\n",
    "import numpy as np\n",
    "\n",
    "def check_punctuation(poem_texts, positions=[5, 11, 17, 23]):\n",
    "    \"\"\"\n",
    "    Check the punctuation in the fixed positions of the poem texts.\n",
    "    It prints the found characters in the fixed positions and identifies any invalid characters.\n",
    "\n",
    "    :param poem_texts: np.ndarray, the array of poem texts\n",
    "    :return: set, invalid punctuations\n",
    "    \"\"\"\n",
    "\n",
    "    # Check the fixed location values\n",
    "    chars_at_fixed_positions = set(poem_texts[:, positions].reshape(-1))\n",
    "    print('Characters found at fixed positions:', ''.join(chars_at_fixed_positions))\n",
    "\n",
    "    # Check the invalid characters\n",
    "    valid_chars = set(\"！，？。\")\n",
    "    invalid_chars = chars_at_fixed_positions - valid_chars\n",
    "    print('Find invalid characters:', ''.join(invalid_chars))\n",
    "\n",
    "    return invalid_chars\n",
    "\n",
    "def clean_poem_texts(poem_texts):\n",
    "    \"\"\"\n",
    "    Clean the poem texts by removing invalid characters and truncating to 24 characters.\n",
    "\n",
    "    :param poem_texts: pd.Series, the series of poem texts\n",
    "    :return: ndarray, cleaned poem texts with shape (n, 24)\n",
    "    \"\"\"\n",
    "    # Adjust the size of every poem item to 24\n",
    "    poems_truncated = poem_texts.map(lambda x: x[:24])\n",
    "\n",
    "    # Check the size less than 24\n",
    "    poems_small = poems_truncated[poems_truncated.str.len() < 24]\n",
    "    if not poems_small.empty:\n",
    "        print('Count of poems with size less than 24:', len(poems_small))\n",
    "        poems_truncated = poems_truncated[poems_truncated.str.len() == 24]\n",
    "\n",
    "    # Transform the pandas Series to numpy array\n",
    "    poem_numpy = np.array(\n",
    "        poems_truncated.map(list).to_list()\n",
    "    )\n",
    "    print('shape of numpy array', poem_numpy.shape)\n",
    "\n",
    "    # Check the signs in the wujue array\n",
    "    invalid_chars = check_punctuation(poem_numpy)\n",
    "\n",
    "    # Find the abnormal items\n",
    "    abnormal_items = poem_numpy[\n",
    "        np.isin(poem_numpy[:, [5, 11, 17, 23]], list(invalid_chars)).any(axis=1)\n",
    "    ]\n",
    "    abnormal_count = len(abnormal_items)\n",
    "    print('abnormal count:', abnormal_count)\n",
    "    if abnormal_count > 0:\n",
    "        print('abnormal item: ', ''.join(abnormal_items[0]))\n",
    "\n",
    "    # Remove the abnormal item\n",
    "    poems_removed_invalid = poem_numpy[\n",
    "        ~np.isin(poem_numpy[:, [5, 11, 17, 23]], list(invalid_chars)).any(axis=1)\n",
    "    ]\n",
    "\n",
    "    print('===== After removing the abnormal items =====')\n",
    "    print('shape of numpy array', poems_removed_invalid.shape)\n",
    "    check_punctuation(poems_removed_invalid)\n",
    "\n",
    "    # Convert back to pandas Series\n",
    "    return poems_removed_invalid"
   ],
   "id": "250d55c9d9594e57",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:56:55.488161Z",
     "start_time": "2025-08-27T06:56:53.400310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Read all files and clean the dataset\n",
    "\n",
    "all_poems = []\n",
    "\n",
    "for file in poem_files:\n",
    "    print(f\"Processing file: {file}\")\n",
    "    poem_texts = read_file_to_df(file)\n",
    "    if poem_texts.empty:\n",
    "        print(\"No valid poems found in this file.\\n\")\n",
    "        continue\n",
    "\n",
    "    result = clean_poem_texts(poem_texts)\n",
    "    all_poems.append(result)\n",
    "    print()\n",
    "\n",
    "# Concatenate all cleaned poems into a single array\n",
    "train_poems_numpy = np.concatenate(all_poems, axis=0)\n",
    "train_poems_numpy.shape"
   ],
   "id": "c85748c0068ea4ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: data/Poetry/诗歌数据集/秦.csv\n",
      "No valid poems found in this file.\n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/先秦.csv\n",
      "No valid poems found in this file.\n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/隋.csv\n",
      "shape of numpy array (71, 24)\n",
      "Characters found at fixed positions: ，？。\n",
      "Find invalid characters: \n",
      "abnormal count: 0\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (71, 24)\n",
      "Characters found at fixed positions: ，？。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/辽.csv\n",
      "No valid poems found in this file.\n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/当代.csv\n",
      "shape of numpy array (1109, 24)\n",
      "Characters found at fixed positions: 华文宵帽冕流？山，栏！鼠大歌边」轻对不。闲传：；\n",
      "Find invalid characters: 华文宵帽鼠大冕流歌边」轻对山不栏闲传：；\n",
      "abnormal count: 13\n",
      "abnormal item:  琅玕经雨青，染绿山溪水。“萧萧我凭栏”，袅袅清歌\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (1096, 24)\n",
      "Characters found at fixed positions: ！，？。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/明_1.csv\n",
      "shape of numpy array (3712, 24)\n",
      "Characters found at fixed positions: 歌幕？丛鹤者兰人相，。》过自月曲金罗\n",
      "Find invalid characters: 歌幕鹤丛人者兰相》过自月曲金罗\n",
      "abnormal count: 5\n",
      "abnormal item:  片舫连双桨，呕哑杂哩罗。惯听吴棹曲，羞杀《阆中歌\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (3707, 24)\n",
      "Characters found at fixed positions: ，？。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/明_2.csv\n",
      "Count of poems with size less than 24: 3\n",
      "shape of numpy array (3829, 24)\n",
      "Characters found at fixed positions: 水，？。\n",
      "Find invalid characters: 水\n",
      "abnormal count: 1\n",
      "abnormal item:  操杵力不任，当垆心自鄙。花时掩关坐，焚香读《秋水\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (3828, 24)\n",
      "Characters found at fixed positions: ，？。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/明_3.csv\n",
      "shape of numpy array (4249, 24)\n",
      "Characters found at fixed positions: 木学？，。传》筝！；\n",
      "Find invalid characters: 木学传筝》；\n",
      "abnormal count: 6\n",
      "abnormal item:  雨馀鸟语凉，斜阳竹深见。频来非看花，借读《高僧传\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (4243, 24)\n",
      "Characters found at fixed positions: ，？。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/清_3.csv\n",
      "shape of numpy array (1882, 24)\n",
      "Characters found at fixed positions: 断伸真饶安生日蛾？敲梅乍通里，1磨遥说！3尔亲撞销旧多思釭诉草近质尽话人轻弱。外得沾；天\n",
      "Find invalid characters: 断伸真饶安生日蛾敲梅乍通里1磨遥说3尔亲撞销旧多思釭诉草近质尽话人轻弱外得沾；天\n",
      "abnormal count: 16\n",
      "abnormal item:  昔子贵之时，曾居洛阳市。洛阳人情何？曰『薄乎云尔\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (1866, 24)\n",
      "Characters found at fixed positions: ！，？。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/清_2.csv\n",
      "shape of numpy array (1473, 24)\n",
      "Characters found at fixed positions: ；？有，。！曲\n",
      "Find invalid characters: 曲；有\n",
      "abnormal count: 4\n",
      "abnormal item:  闻君向南投，曾过北投宿。试从鹿水头，一续「乌溪曲\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (1469, 24)\n",
      "Characters found at fixed positions: ！，？。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/明_4.csv\n",
      "shape of numpy array (2184, 24)\n",
      "Characters found at fixed positions: ？，皇。天\n",
      "Find invalid characters: 皇天\n",
      "abnormal count: 1\n",
      "abnormal item:  去去去此间，不是留侬处。侬住三十三天天外天，玉皇\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (2183, 24)\n",
      "Characters found at fixed positions: ，？。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/元.csv\n",
      "shape of numpy array (2624, 24)\n",
      "Characters found at fixed positions: 篇两苧曲赋？梅海相，！南浮广枝扇歌经星。：痕\n",
      "Find invalid characters: 篇南两浮广苧曲枝扇赋歌梅海相经星：痕\n",
      "abnormal count: 9\n",
      "abnormal item:  老竹空岩里，悬厓飞水前。欲识逍遥境，试读《逍遥篇\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (2615, 24)\n",
      "Characters found at fixed positions: ！，？。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/清_1.csv\n",
      "shape of numpy array (1711, 24)\n",
      "Characters found at fixed positions: ；水？人鹤箫，。城！潮杜\n",
      "Find invalid characters: 水鹤人箫城潮；杜\n",
      "abnormal count: 4\n",
      "abnormal item:  昔作秦淮客，朱楼赋《洞箫》。白头故人尽，重上石城\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (1707, 24)\n",
      "Characters found at fixed positions: ！，？。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/南北朝.csv\n",
      "shape of numpy array (1, 24)\n",
      "Characters found at fixed positions: ，。\n",
      "Find invalid characters: \n",
      "abnormal count: 0\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (1, 24)\n",
      "Characters found at fixed positions: ，。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/宋_1.csv\n",
      "shape of numpy array (4397, 24)\n",
      "Characters found at fixed positions: 桨前莲，。；\n",
      "Find invalid characters: 桨；前莲\n",
      "abnormal count: 2\n",
      "abnormal item:  晚过鸳鸯浦，无心唱《采莲》。莫嗔兰桨急，为要趁前\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (4395, 24)\n",
      "Characters found at fixed positions: ，。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/宋_2.csv\n",
      "shape of numpy array (3470, 24)\n",
      "Characters found at fixed positions: ，。\n",
      "Find invalid characters: \n",
      "abnormal count: 0\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (3470, 24)\n",
      "Characters found at fixed positions: ，。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/唐.csv\n",
      "shape of numpy array (2711, 24)\n",
      "Characters found at fixed positions: ？沽此，。！\n",
      "Find invalid characters: 沽此\n",
      "abnormal count: 1\n",
      "abnormal item:  勒马问樵夫，前村酒有无。「杜康家在此，一任君来沽\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (2710, 24)\n",
      "Characters found at fixed positions: ！，？。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/近现代.csv\n",
      "shape of numpy array (398, 24)\n",
      "Characters found at fixed positions: ？，。！；\n",
      "Find invalid characters: ；\n",
      "abnormal count: 1\n",
      "abnormal item:  明月照秋霜，今朝还故乡；留得头颅在，雄心誓不降。\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (397, 24)\n",
      "Characters found at fixed positions: ！，？。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/宋_3.csv\n",
      "shape of numpy array (3005, 24)\n",
      "Characters found at fixed positions: ？灯个，。花懒曲\n",
      "Find invalid characters: 花灯个懒曲\n",
      "abnormal count: 3\n",
      "abnormal item:  明月入我池，皎皎铺纻缟。何日变成缁？《太玄》吾懒\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (3002, 24)\n",
      "Characters found at fixed positions: ，？。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/汉.csv\n",
      "No valid poems found in this file.\n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/金.csv\n",
      "shape of numpy array (252, 24)\n",
      "Characters found at fixed positions: ，。\n",
      "Find invalid characters: \n",
      "abnormal count: 0\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (252, 24)\n",
      "Characters found at fixed positions: ，。\n",
      "Find invalid characters: \n",
      "\n",
      "Processing file: data/Poetry/诗歌数据集/魏晋.csv\n",
      "No valid poems found in this file.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(37012, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Dataset to token id sequences",
   "id": "44dc0adc2c6c2704"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:56:56.912316Z",
     "start_time": "2025-08-27T06:56:55.548150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import layers\n",
    "\n",
    "tv = layers.TextVectorization(\n",
    "    max_tokens=10000,\n",
    "    standardize=None,\n",
    "    split=None, # 直接喂二维数组\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=24\n",
    ")\n",
    "tv.adapt(train_poems_numpy)"
   ],
   "id": "c890cc6fbcb7117",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 14:56:55.713320: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-27 14:56:55.720556: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1756277815.728456   12689 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1756277815.731286   12689 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1756277815.738430   12689 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756277815.738439   12689 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756277815.738441   12689 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1756277815.738442   12689 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-27 14:56:55.741120: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "I0000 00:00:1756277816.760353   12689 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 14125 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:56:57.336322Z",
     "start_time": "2025-08-27T06:56:56.965304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Demo usage of tv\n",
    "\n",
    "# Print the vocabulary\n",
    "print('Vocabulary size:', tv.vocabulary_size())\n",
    "print('Vocabulary:', ''.join(tv.get_vocabulary()[:20]))\n",
    "\n",
    "# Encode\n",
    "encoded = tv(train_poems_numpy[0])\n",
    "\n",
    "# Decode\n",
    "vocab = tv.get_vocabulary()\n",
    "decoded =[vocab[i] for i in encoded]\n",
    "print('Encoded:', encoded.numpy())\n",
    "print('Decoded:', ''.join(decoded))"
   ],
   "id": "ef849f42f169ce1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 6350\n",
      "Vocabulary: [UNK]，。不人山风一花无来何云有日月春水中\n",
      "Encoded: [1152 1152  948  466   65    2 1074  177  740   41  604    3 1103   64\n",
      "    6   16 1230    2  945 2176  183    7   23    3]\n",
      "Decoded: 脉脉广川流，驱马历长洲。鹊飞山月曙，蝉噪野风秋。\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:56:57.471525Z",
     "start_time": "2025-08-27T06:56:57.394355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode all the poems\n",
    "train_token_ids = tv(train_poems_numpy)\n",
    "print('shape of wujue_token_ids:', train_token_ids.shape)"
   ],
   "id": "8277b7ae292b1f71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of wujue_token_ids: (37012, 24)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Build the LSTM Decoder model",
   "id": "6145e1fc59ad943a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:56:57.567060Z",
     "start_time": "2025-08-27T06:56:57.551231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the train dataset\n",
    "train_sequences = train_token_ids[:, :-1]\n",
    "target_sequences = train_token_ids[:, 1:]\n",
    "\n",
    "train_sequences.shape, target_sequences.shape"
   ],
   "id": "43b8b72f51002c3b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([37012, 23]), TensorShape([37012, 23]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:56:58.131943Z",
     "start_time": "2025-08-27T06:56:57.659114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build a simple LSTM Decoder model\n",
    "\n",
    "import keras\n",
    "from keras import models, layers\n",
    "\n",
    "def build_model(vocab_size):\n",
    "    inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"inputs\")\n",
    "    x = layers.Embedding(input_dim=vocab_size, output_dim=100, name=\"embedding\")(inputs)\n",
    "    x = layers.LSTM(512, return_sequences=True, name=\"lstm\")(x)\n",
    "    x = layers.Dropout(0.1, name=\"dropout\")(x)\n",
    "    outputs = layers.Dense(vocab_size, activation=\"softmax\", name=\"output\")(x)\n",
    "\n",
    "    return models.Model(inputs=inputs, outputs=outputs, name=\"lstm_decoder\")\n",
    "\n",
    "model = build_model(tv.vocabulary_size())\n",
    "model.summary()"
   ],
   "id": "75954408bd3f32c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"lstm_decoder\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_decoder\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inputs (\u001B[38;5;33mInputLayer\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001B[38;5;33mEmbedding\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)      │       \u001B[38;5;34m635,000\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │     \u001B[38;5;34m1,255,424\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001B[38;5;33mDropout\u001B[0m)               │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)      │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m6350\u001B[0m)     │     \u001B[38;5;34m3,257,550\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">635,000</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,255,424</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6350</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,257,550</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m5,147,974\u001B[0m (19.64 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,147,974</span> (19.64 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m5,147,974\u001B[0m (19.64 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,147,974</span> (19.64 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:56:59.634121Z",
     "start_time": "2025-08-27T06:56:58.234264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the sample generate function\n",
    "def generate(prompt, max_length=24, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generate a poem based on the start prompt\n",
    "\n",
    "    Returns:\n",
    "        A generated poem as a string.\n",
    "    \"\"\"\n",
    "    prompt_inputs = list(prompt)\n",
    "    generated = tv(prompt_inputs)[:len(prompt)].numpy().tolist()\n",
    "    while len(generated) < max_length:\n",
    "        input_sequence = np.array(generated).reshape(1, -1)\n",
    "        predictions = model.predict(input_sequence, verbose=0)[0]\n",
    "        next_token_id = sample(predictions[-1], temperature)\n",
    "        generated.append(next_token_id)\n",
    "    return ''.join(tv.get_vocabulary()[token_id] for token_id in generated)\n",
    "\n",
    "def sample(predictions, temperature=1.0, eps1=1e-20, eps2=1e-9):\n",
    "    p = np.asarray(predictions, dtype=np.float64)\n",
    "\n",
    "    # The two key points: log(p + eps1) divide by (T + eps2)\n",
    "    logits = np.log(p + eps1) / (float(temperature) + eps2)\n",
    "\n",
    "    # Subtract the max logit to prevent overflow\n",
    "    logits -= np.max(logits)\n",
    "\n",
    "    q = np.exp(logits)\n",
    "    q /= q.sum()\n",
    "    return int(np.random.choice(len(q), p=q))\n",
    "\n",
    "\n",
    "generate(\"海外\", temperature=0)"
   ],
   "id": "2145bf31d5cc14b2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1756277818.662833   12767 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'海外薛歃嗅怏踵七毂吊枑穸臬痼埭多多受豁薾豁薾蕨噀'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T06:56:59.679240Z",
     "start_time": "2025-08-27T06:56:59.673877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define callback to print the sample generative poem every 10 epochs\n",
    "class PoetryGenerateCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, epochs):\n",
    "        super().__init__()\n",
    "        self.generating_epochs = self._get_generating_epochs(epochs)\n",
    "        self.generated_poems = {}\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch += 1\n",
    "        if epoch not in self.generating_epochs:\n",
    "            return\n",
    "        poems = self.generate_poems()\n",
    "        self.generated_poems[epoch] = {\n",
    "            'poems': poems,\n",
    "            'logs': logs\n",
    "        }\n",
    "\n",
    "        self.print_poems(poems)\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_poems():\n",
    "        temperatures = [0, 0.5, 1.0, 1.5]\n",
    "        generated_texts = [\n",
    "            generate('海外', max_length=24, temperature=temp)\n",
    "            for temp in temperatures\n",
    "        ]\n",
    "        return [{ 'temperature': temperature, 'text': text } for temperature, text in zip(temperatures, generated_texts)]\n",
    "\n",
    "    @staticmethod\n",
    "    def print_poems(poems):\n",
    "        for item in poems:\n",
    "            print(f\"temperature {item['temperature']:.1f}: {item['text']}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_generating_epochs(epochs):\n",
    "        if epochs % 2 != 0:\n",
    "            print(\"Warning: epochs should be even number.\")\n",
    "\n",
    "        mid_epoch = epochs // 2\n",
    "        left_generating_epochs = [2**i for i in range(0, int(np.log2(mid_epoch)) + 1)]\n",
    "        if mid_epoch not in left_generating_epochs:\n",
    "            left_generating_epochs.append(mid_epoch)\n",
    "\n",
    "        right_generating_epochs = [1 + epochs - e for e in left_generating_epochs][::-1]\n",
    "        return left_generating_epochs + right_generating_epochs"
   ],
   "id": "c3bcded08b52ca33",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T07:08:16.381556Z",
     "start_time": "2025-08-27T06:56:59.775861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 50\n",
    "poetry_callback = PoetryGenerateCallback(epochs)\n",
    "\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    train_sequences,\n",
    "    target_sequences,\n",
    "    batch_size=256,\n",
    "    epochs=epochs,\n",
    "    callbacks=[],\n",
    "    verbose=2\n",
    ")"
   ],
   "id": "9942b787f254ced1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "145/145 - 15s - 103ms/step - accuracy: 0.0961 - loss: 6.5784\n",
      "Epoch 2/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.1420 - loss: 5.8895\n",
      "Epoch 3/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.1775 - loss: 5.7291\n",
      "Epoch 4/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.1918 - loss: 5.6292\n",
      "Epoch 5/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.1953 - loss: 5.5501\n",
      "Epoch 6/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.1980 - loss: 5.4718\n",
      "Epoch 7/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2021 - loss: 5.3731\n",
      "Epoch 8/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2073 - loss: 5.2727\n",
      "Epoch 9/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2118 - loss: 5.1933\n",
      "Epoch 10/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2155 - loss: 5.1308\n",
      "Epoch 11/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2193 - loss: 5.0736\n",
      "Epoch 12/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2235 - loss: 5.0187\n",
      "Epoch 13/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2271 - loss: 4.9678\n",
      "Epoch 14/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2310 - loss: 4.9187\n",
      "Epoch 15/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2346 - loss: 4.8724\n",
      "Epoch 16/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2377 - loss: 4.8280\n",
      "Epoch 17/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2411 - loss: 4.7841\n",
      "Epoch 18/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2445 - loss: 4.7423\n",
      "Epoch 19/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2479 - loss: 4.7020\n",
      "Epoch 20/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2507 - loss: 4.6624\n",
      "Epoch 21/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2538 - loss: 4.6237\n",
      "Epoch 22/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2565 - loss: 4.5856\n",
      "Epoch 23/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2592 - loss: 4.5491\n",
      "Epoch 24/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2618 - loss: 4.5136\n",
      "Epoch 25/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2647 - loss: 4.4782\n",
      "Epoch 26/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2671 - loss: 4.4432\n",
      "Epoch 27/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2695 - loss: 4.4099\n",
      "Epoch 28/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2720 - loss: 4.3771\n",
      "Epoch 29/50\n",
      "145/145 - 14s - 94ms/step - accuracy: 0.2744 - loss: 4.3458\n",
      "Epoch 30/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2764 - loss: 4.3152\n",
      "Epoch 31/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2786 - loss: 4.2860\n",
      "Epoch 32/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2808 - loss: 4.2564\n",
      "Epoch 33/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2829 - loss: 4.2284\n",
      "Epoch 34/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2851 - loss: 4.2002\n",
      "Epoch 35/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2872 - loss: 4.1734\n",
      "Epoch 36/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2890 - loss: 4.1470\n",
      "Epoch 37/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2911 - loss: 4.1202\n",
      "Epoch 38/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2935 - loss: 4.0939\n",
      "Epoch 39/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.2951 - loss: 4.0697\n",
      "Epoch 40/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2972 - loss: 4.0446\n",
      "Epoch 41/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.2991 - loss: 4.0198\n",
      "Epoch 42/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.3012 - loss: 3.9956\n",
      "Epoch 43/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.3034 - loss: 3.9722\n",
      "Epoch 44/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.3051 - loss: 3.9487\n",
      "Epoch 45/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.3076 - loss: 3.9262\n",
      "Epoch 46/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.3093 - loss: 3.9032\n",
      "Epoch 47/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.3112 - loss: 3.8795\n",
      "Epoch 48/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.3132 - loss: 3.8588\n",
      "Epoch 49/50\n",
      "145/145 - 14s - 93ms/step - accuracy: 0.3157 - loss: 3.8367\n",
      "Epoch 50/50\n",
      "145/145 - 13s - 93ms/step - accuracy: 0.3173 - loss: 3.8162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4d0b96fef0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T07:08:16.543779Z",
     "start_time": "2025-08-27T07:08:16.456347Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the generated poems for analysis\n",
    "# poetry_callback.generated_poems\n",
    "\n",
    "# Or save the model\n",
    "model.save('lstm_poetry_model.keras')"
   ],
   "id": "75a3c4ceb1ad12d4",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. Using the model to generate poems",
   "id": "dada31118ce72d4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Reload the model\n",
    "model = keras.models.load_model('lstm_poetry_model.keras', compile=False)"
   ],
   "id": "76edf563676fd6c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T07:29:39.104191Z",
     "start_time": "2025-08-27T07:29:35.557230Z"
    }
   },
   "cell_type": "code",
   "source": [
    "poems = PoetryGenerateCallback.generate_poems()\n",
    "PoetryGenerateCallback.print_poems(poems)"
   ],
   "id": "d1d91eaf6923169e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temperature 0.0: 海外一天地，江南万里来。西风吹不尽，吹笛一枝秋。\n",
      "temperature 0.5: 海外草云深，山空云雾重。不知天外景，风雨暗中流。\n",
      "temperature 1.0: 海外春气晚，夕阳春水发。途人骨束堆，竹间江头绿。\n",
      "temperature 1.5: 海外负银川，较游穷怨望。楚江海轮行，呼綵七茅屋。\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
