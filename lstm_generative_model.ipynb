{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Use LSTM to generate the poem\n",
    "\n",
    "The procedure:\n",
    "\n",
    "1. Embedding Layer;\n",
    "2. LSTM Decoder-only;\n",
    "3. Sample for generation;\n",
    "4. Use all data to train, which overfits the training data."
   ],
   "id": "67d05df12625237f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1. Download The Dataset",
   "id": "243f99368fd6af89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:59:43.284735Z",
     "start_time": "2025-08-19T09:52:13.559894Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Download the dataset\n",
    "!mkdir -p data\n",
    "!wget -nv --show-progress https://raw.githubusercontent.com/xiu-ze/Poetry/refs/heads/main/%E8%AF%97%E6%AD%8C%E6%95%B0%E6%8D%AE%E9%9B%86/%E5%94%90.csv -O data/tang_poetry.csv"
   ],
   "id": "ec812b7f9a677dcb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/tang_poetry.cs  15%[==>                 ]   1.88M  90.1KB/s    in 6m 29s  \r\n",
      "data/tang_poetry.cs 100%[+++================>]  11.90M   204KB/s    in 58s     \r\n",
      "2025-08-19 17:59:43 URL:https://raw.githubusercontent.com/xiu-ze/Poetry/refs/heads/main/%E8%AF%97%E6%AD%8C%E6%95%B0%E6%8D%AE%E9%9B%86/%E5%94%90.csv [12482729/12482729] -> \"data/tang_poetry.csv\" [2]\r\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:59:44.544353Z",
     "start_time": "2025-08-19T09:59:43.561141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "file = os.path.expanduser('data/tang_poetry.csv')\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "filter_by_wujue = df[df[\"体裁\"].astype(str).str.contains(\"五言绝句\", na=False)].copy()\n",
    "wujue = filter_by_wujue['内容']\n",
    "wujue[:10]"
   ],
   "id": "52b62e20603536f7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25    写书今日了，先生莫嫌迟。明朝是假日，早放学生归。\n",
       "26    他道侧书易，我道侧书难。侧书还侧读，还须侧眼看。\n",
       "36    攀藤招逸客，偃桂协幽情。水中看树影，风里听松声。\n",
       "37    携琴侍叔夜，负局访安期。不应题石壁，为记赏山时。\n",
       "38    泉石多仙趣，岩壑写奇形。欲知堪悦耳，唯听水泠泠。\n",
       "39    岩壑恣登临，莹目复怡心。风篁类长笛，流水当鸣琴。\n",
       "40    懒步天台路，惟登地肺山。幽岩仙桂满，今日恣情攀。\n",
       "41    暂游仁智所，萧然松桂情。寄言栖遁客，勿复访蓬瀛。\n",
       "42    瀑溜晴疑雨，丛篁昼似昏。山中真可玩，暂请报王孙。\n",
       "43    傍池聊试笔，倚石旋题诗。豫弹山水调，终拟从钟期。\n",
       "Name: 内容, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. Clean the dataset\n",
    "\n",
    "1. Truncate the poems to 24 characters;\n",
    "2. Check the invalid signs in the fixed positions and remove the abnormal items."
   ],
   "id": "67716901997dc298"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:59:45.126072Z",
     "start_time": "2025-08-19T09:59:45.075601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Transform the pandas Series to numpy array and check\n",
    "import numpy as np\n",
    "\n",
    "def check_wujue_signs(wujue_array):\n",
    "    # Check the fixed location values\n",
    "    signs_in_wujue = set(wujue_array[:, [5, 11, 17, 23]].reshape(-1))\n",
    "    print('signs in wujue:', ''.join(signs_in_wujue))\n",
    "\n",
    "    # There are abnormal sign in specific locations\n",
    "    valid_chars = set(\"！，？。\")\n",
    "    invalid_chars = signs_in_wujue - valid_chars\n",
    "    print('invalid signs:', ''.join(invalid_chars))\n",
    "\n",
    "    return invalid_chars\n",
    "\n",
    "# Adjust the size of every poem item to 24\n",
    "wujue_truncated = wujue.map(lambda x: x[:24])\n",
    "\n",
    "# Transform the pandas Series to numpy array\n",
    "wujue_array = np.array(\n",
    "    wujue_truncated.map(list).to_list()\n",
    ")\n",
    "print('shape of numpy array', wujue_array.shape)\n",
    "\n",
    "# Check the signs in the wujue array\n",
    "invalid_chars = check_wujue_signs(wujue_array)\n",
    "\n",
    "# Find the abnormal items\n",
    "abnormal_items = wujue_array[\n",
    "    np.isin(wujue_array[:, [5, 11, 17, 23]], list(invalid_chars)).any(axis=1)\n",
    "]\n",
    "print('abnormal count:', len(abnormal_items))\n",
    "print('abnormal item: ', ''.join(abnormal_items[0]))\n",
    "\n",
    "# Remove the abnormal item\n",
    "wujue_array = wujue_array[\n",
    "    ~np.isin(wujue_array[:, [5, 11, 17, 23]], list(invalid_chars)).any(axis=1)\n",
    "]\n",
    "\n",
    "print('===== After removing the abnormal items =====')\n",
    "print('shape of numpy array', wujue_array.shape)\n",
    "check_wujue_signs(wujue_array)"
   ],
   "id": "250d55c9d9594e57",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of numpy array (2711, 24)\n",
      "signs in wujue: 。！？，沽此\n",
      "invalid signs: 沽此\n",
      "abnormal count: 1\n",
      "abnormal item:  勒马问樵夫，前村酒有无。「杜康家在此，一任君来沽\n",
      "===== After removing the abnormal items =====\n",
      "shape of numpy array (2710, 24)\n",
      "signs in wujue: ？，。！\n",
      "invalid signs: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 3. Dataset to token id sequences",
   "id": "44dc0adc2c6c2704"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:59:54.771653Z",
     "start_time": "2025-08-19T09:59:45.187308Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from keras import layers\n",
    "\n",
    "tv = layers.TextVectorization(\n",
    "    max_tokens=10000,\n",
    "    standardize=None,\n",
    "    split=\"character\",\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=24\n",
    ")\n",
    "tv.adapt(wujue_truncated)"
   ],
   "id": "c890cc6fbcb7117",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 17:59:48.784165: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:59:56.498958Z",
     "start_time": "2025-08-19T09:59:56.445657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Demo usage of tv\n",
    "\n",
    "# Print the vocabulary\n",
    "print('Vocabulary size:', tv.vocabulary_size())\n",
    "print('Vocabulary:', ''.join(tv.get_vocabulary()[:20]))\n",
    "\n",
    "# Encode\n",
    "encoded = tv(wujue_truncated.values[0])\n",
    "\n",
    "# Decode\n",
    "vocab = tv.get_vocabulary()\n",
    "decoded =[vocab[i] for i in encoded]\n",
    "print('Encoded:', encoded.numpy())\n",
    "print('Decoded:', ''.join(decoded))"
   ],
   "id": "ef849f42f169ce1f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: [UNK]，。不人风山一无日何花来春水月中上知\n",
      "Encoded: [1230  202   44   10 1137    2  297   42   67  608  323    3   48   85\n",
      "   38 1001   10    2  288  576  441   42   40    3]\n",
      "Decoded: 写书今日了，先生莫嫌迟。明朝是假日，早放学生归。\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:59:56.619094Z",
     "start_time": "2025-08-19T09:59:56.579940Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Encode all the poems\n",
    "wujue_token_ids = tv(wujue_truncated.values)\n",
    "print('shape of wujue_token_ids:', wujue_token_ids.shape)"
   ],
   "id": "8277b7ae292b1f71",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of wujue_token_ids: (2711, 24)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 4. Build the LSTM Decoder model",
   "id": "6145e1fc59ad943a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T09:59:57.206802Z",
     "start_time": "2025-08-19T09:59:57.198372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Prepare the train dataset\n",
    "train_sequences = wujue_token_ids[:, :-1]\n",
    "target_sequences = wujue_token_ids[:, 1:]\n",
    "\n",
    "train_sequences.shape, target_sequences.shape"
   ],
   "id": "43b8b72f51002c3b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2711, 23]), TensorShape([2711, 23]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T13:34:23.688312Z",
     "start_time": "2025-08-19T13:34:23.609681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build a simple LSTM Decoder model\n",
    "\n",
    "import keras\n",
    "from keras import models, layers\n",
    "\n",
    "def build_model(vocab_size):\n",
    "    inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"inputs\")\n",
    "    x_embedded = layers.Embedding(\n",
    "        input_dim=vocab_size, output_dim=100, name=\"embedding\"\n",
    "    )(inputs)\n",
    "    x_lstm_output = layers.LSTM(\n",
    "        128, return_sequences=True, name=\"lstm\"\n",
    "    )(x_embedded)\n",
    "    outputs = layers.Dense(\n",
    "        vocab_size, activation=\"softmax\", name=\"output\"\n",
    "    )(x_lstm_output)\n",
    "\n",
    "    return models.Model(inputs=inputs, outputs=outputs, name=\"lstm_decoder\")\n",
    "\n",
    "model = build_model(tv.vocabulary_size())\n",
    "model.summary()\n"
   ],
   "id": "75954408bd3f32c2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"lstm_decoder\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"lstm_decoder\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inputs (\u001B[38;5;33mInputLayer\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (\u001B[38;5;33mEmbedding\u001B[0m)           │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m100\u001B[0m)      │       \u001B[38;5;34m322,600\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001B[38;5;33mLSTM\u001B[0m)                     │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m128\u001B[0m)      │       \u001B[38;5;34m117,248\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001B[38;5;33mDense\u001B[0m)                  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3226\u001B[0m)     │       \u001B[38;5;34m416,154\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ inputs (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">322,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">117,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3226</span>)     │       <span style=\"color: #00af00; text-decoration-color: #00af00\">416,154</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m856,002\u001B[0m (3.27 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">856,002</span> (3.27 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m856,002\u001B[0m (3.27 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">856,002</span> (3.27 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T13:29:43.336435Z",
     "start_time": "2025-08-19T13:29:41.363252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the sample generate function\n",
    "def generate(prompt, max_length=24, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generate a poem based on the start prompt\n",
    "\n",
    "    Returns:\n",
    "        A generated poem as a string.\n",
    "    \"\"\"\n",
    "    generated = tv(prompt)[:len(prompt)].numpy().tolist()\n",
    "    while len(generated) < max_length:\n",
    "        input_sequence = np.array(generated).reshape(1, -1)\n",
    "        predictions = model.predict(input_sequence, verbose=0)[0]\n",
    "        next_token_id = sample(predictions[-1], temperature)\n",
    "        generated.append(next_token_id)\n",
    "    return ''.join(tv.get_vocabulary()[token_id] for token_id in generated)\n",
    "\n",
    "def sample(predictions, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Sample a token from the predictions with temperature scaling.\n",
    "    \"\"\"\n",
    "    predictions = np.asarray(predictions).astype(\"float64\")\n",
    "    predictions = np.log(predictions) / temperature\n",
    "    exp_preds = np.exp(predictions)\n",
    "    predictions = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, predictions, 1)\n",
    "    return np.argmax(probas[0])\n",
    "\n",
    "def sample(predictions, temperature=1.0, eps1=1e-20, eps2=1e-9):\n",
    "    p = np.asarray(predictions, dtype=np.float64)\n",
    "\n",
    "    # The two key points: log(p + eps1) divide by (T + eps2)\n",
    "    logits = np.log(p + eps1) / (float(temperature) + eps2)\n",
    "\n",
    "    # Subtract the max logit to prevent overflow\n",
    "    logits -= np.max(logits)\n",
    "\n",
    "    q = np.exp(logits)\n",
    "    q /= q.sum()\n",
    "    return int(np.random.choice(len(q), p=q))\n",
    "\n",
    "\n",
    "generate(\"海外\", temperature=0)"
   ],
   "id": "2145bf31d5cc14b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'海外不山里，不是不人人。不知不不处，不是不人人。'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T13:34:15.910735Z",
     "start_time": "2025-08-19T13:34:15.904997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define callback to print the sample generative poem every 10 epochs\n",
    "class PoetryGenerateCallback(keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.next_print_epoch = 1\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        epoch += 1\n",
    "        if epoch != self.next_print_epoch:\n",
    "            return\n",
    "\n",
    "        print(f\"Generating poems at epoch {epoch + 1}:\\n\")\n",
    "        self._print_generated_poems()\n",
    "        self.next_print_epoch *= 2\n",
    "\n",
    "    @staticmethod\n",
    "    def _print_generated_poems():\n",
    "        temperatures = [0, 0.5, 1.0, 1.5]\n",
    "        generated_texts = [\n",
    "            generate('海外', max_length=24, temperature=temp)\n",
    "            for temp in temperatures\n",
    "        ]\n",
    "\n",
    "        for temp, text in zip(temperatures, generated_texts):\n",
    "            print(f\"temperature {temp}:{text}\\n\")"
   ],
   "id": "c3bcded08b52ca33",
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T13:36:33.731807Z",
     "start_time": "2025-08-19T13:34:36.364236Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.fit(\n",
    "    train_sequences,\n",
    "    target_sequences,\n",
    "    batch_size=64,\n",
    "    epochs=10,\n",
    "    callbacks=[PoetryGenerateCallback()],\n",
    "    verbose=2\n",
    ")"
   ],
   "id": "9942b787f254ced1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "Generated poem with temperature 0:\n",
      "海外。。。。。。。。。。。。。。。。。。。。。。\n",
      "\n",
      "Generated poem with temperature 0.5:\n",
      "海外缩寂，，，，愁，。，，。。。。，。，。，。不\n",
      "\n",
      "Generated poem with temperature 1.0:\n",
      "海外早和医峡小城，二。，满。辞数。垂。有寒。饥嗟\n",
      "\n",
      "Generated poem with temperature 1.5:\n",
      "海外萧虑静泪舟残逗动弄亭禄枯草渺逐彭苦甘撩无生犹\n",
      "\n",
      "43/43 - 13s - 307ms/step - accuracy: 0.0855 - loss: 7.2277\n",
      "Epoch 2/10\n",
      "Generated poem with temperature 0:\n",
      "海外，，。。。。。。。。。。。。。。。。。。。。\n",
      "\n",
      "Generated poem with temperature 0.5:\n",
      "海外情水。。。，。。。家，，。，。。时。，。。，\n",
      "\n",
      "Generated poem with temperature 1.0:\n",
      "海外逢弃白天。浮。株年旧渔我人嫌唯，，三送，，起\n",
      "\n",
      "Generated poem with temperature 1.5:\n",
      "海外透松待客财碧黄肠应谈羡争尽终容子语侧范高欲叠\n",
      "\n",
      "43/43 - 11s - 256ms/step - accuracy: 0.0902 - loss: 6.3583\n",
      "Epoch 3/10\n",
      "Generated poem with temperature 0:\n",
      "海外，，，。，。，。，。，。，。，。，。，。，。\n",
      "\n",
      "Generated poem with temperature 0.5:\n",
      "海外溪，，，。。。，人，，，。。。。，。，。。。\n",
      "\n",
      "Generated poem with temperature 1.0:\n",
      "海外越时韵年。，乡颓龙君独齐君远不阁年。望水附，\n",
      "\n",
      "Generated poem with temperature 1.5:\n",
      "海外联鸡檐劣棋辈璧用舞，教趣月心喜忍终婉危。每实\n",
      "\n",
      "43/43 - 11s - 263ms/step - accuracy: 0.0939 - loss: 6.3154\n",
      "Epoch 4/10\n",
      "Generated poem with temperature 0:\n",
      "海外，，，，，，，，，，，，，，，，，，，，，，\n",
      "\n",
      "Generated poem with temperature 0.5:\n",
      "海外，，，。，。，，，。，，来，。。，。，，，，\n",
      "\n",
      "Generated poem with temperature 1.0:\n",
      "海外欲正得采登，娟意地。云不病山下不人岁江日，应\n",
      "\n",
      "Generated poem with temperature 1.5:\n",
      "海外憔粟中苔妆诸着筵我今藤宁圆幕衰宝堂方婉柳影性\n",
      "\n",
      "43/43 - 12s - 271ms/step - accuracy: 0.0939 - loss: 6.2996\n",
      "Epoch 5/10\n",
      "Generated poem with temperature 0:\n",
      "海外，，，，，，，，，，，，，，，，，，，，，，\n",
      "\n",
      "Generated poem with temperature 0.5:\n",
      "海外去。，王，。日，，。年，，，不。。，是。，，\n",
      "\n",
      "Generated poem with temperature 1.0:\n",
      "海外绵不引朝芳灯非夕解问眼嫁意，鹬歌。臼，瘴欲有\n",
      "\n",
      "Generated poem with temperature 1.5:\n",
      "海外彫市坏灾乱竞图思宵崦荔传，六贺物陁腰法欲尽辞\n",
      "\n",
      "43/43 - 12s - 275ms/step - accuracy: 0.0941 - loss: 6.2780\n",
      "Epoch 6/10\n",
      "Generated poem with temperature 0:\n",
      "海外。，，，，，，，，，，，，，，，，，，，，，\n",
      "\n",
      "Generated poem with temperature 0.5:\n",
      "海外，，。落。更，树。。直，。未，一。。能云。自\n",
      "\n",
      "Generated poem with temperature 1.0:\n",
      "海外青财行曾动视初那行时自疑。你何日无此曙连潺贞\n",
      "\n",
      "Generated poem with temperature 1.5:\n",
      "海外国五马此，承正光阁池圣庾瞻臼鸟问厌滴钩兰别幌\n",
      "\n",
      "43/43 - 11s - 264ms/step - accuracy: 0.0929 - loss: 6.2353\n",
      "Epoch 7/10\n",
      "Generated poem with temperature 0:\n",
      "海外。不不。不不。不不。不不。不不。不不。不不。\n",
      "\n",
      "Generated poem with temperature 0.5:\n",
      "海外，到。风林。多，空时水一，，机，唯逢，不明，\n",
      "\n",
      "Generated poem with temperature 1.0:\n",
      "海外携取渡。青长勿卑光斜，此敬。诵软交前来。卫喜\n",
      "\n",
      "Generated poem with temperature 1.5:\n",
      "海外母沙空。尽救愚尺泥泊萍迤雾。会吹谓巾岁花帘用\n",
      "\n",
      "43/43 - 12s - 288ms/step - accuracy: 0.0974 - loss: 6.1412\n",
      "Epoch 8/10\n",
      "Generated poem with temperature 0:\n",
      "海外。不不不。不不不。不不不。不不不。不不不。不\n",
      "\n",
      "Generated poem with temperature 0.5:\n",
      "海外。不山醉知。不终人是是，不南只上。无何来花不\n",
      "\n",
      "Generated poem with temperature 1.0:\n",
      "海外烟海。橤风独不黄昨里。赤竹去烟白，将两唯日口\n",
      "\n",
      "Generated poem with temperature 1.5:\n",
      "海外远。双鬟恣栖筠。反莫迥知渡箨幽映南西庙怅锡低\n",
      "\n",
      "43/43 - 11s - 265ms/step - accuracy: 0.1033 - loss: 6.0001\n",
      "Epoch 9/10\n",
      "Generated poem with temperature 0:\n",
      "海外不。不不不。不不不。不不不。不不不。不不不。\n",
      "\n",
      "Generated poem with temperature 0.5:\n",
      "海外不。不日能相。不望秦。何不湿来别。不无南风，\n",
      "\n",
      "Generated poem with temperature 1.0:\n",
      "海外旗水。皆西道。花唯为锦高，中无内年人。得复谋\n",
      "\n",
      "Generated poem with temperature 1.5:\n",
      "海外论依侣边眉。商痕钻摊。保通古袅肝冬涤罗。下新\n",
      "\n",
      "43/43 - 12s - 290ms/step - accuracy: 0.1122 - loss: 5.8915\n",
      "Epoch 10/10\n",
      "Generated poem with temperature 0:\n",
      "海外不。不不不不。不不不不。不不不不。不不不不。\n",
      "\n",
      "Generated poem with temperature 0.5:\n",
      "海外年日，不到不知初，自水州不，夜还春日宿。风见\n",
      "\n",
      "Generated poem with temperature 1.0:\n",
      "海外恍虽。火遣暮乘林，去寂住逢外。更竹出欲量风。\n",
      "\n",
      "Generated poem with temperature 1.5:\n",
      "海外花□作贝，朝岂乾改睇紫意，史晚又褐公名浓国，\n",
      "\n",
      "43/43 - 11s - 251ms/step - accuracy: 0.1240 - loss: 5.8178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14f81b740>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 5. Using the model to generate poems",
   "id": "dada31118ce72d4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T13:40:41.247872Z",
     "start_time": "2025-08-19T13:40:39.524601Z"
    }
   },
   "cell_type": "code",
   "source": "generate('海外')",
   "id": "3fdb53c883b8a409",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'海外声春落。已为莹别若，虽二难幕争。写夜渔薜白，'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
