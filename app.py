# app.py
# -*- coding: utf-8 -*-
"""
æç®€äº”è¨€ç»å¥ç”Ÿæˆï¼ˆæ¨ç†ç‰ˆï¼Œå«å‰ç½®æç¤ºè¯ï¼‰
- å¿…å¡«ï¼šå‰ç½®æç¤ºè¯ï¼ˆè‡³å°‘ 1 ä¸ªå­—ï¼‰
- å›ºå®šæ€»å­—æ•°ï¼š24ï¼ˆåŒ…å«å‰ç½®æç¤ºè¯ï¼‰
- åªå±•ç¤ºæ ¼å¼åŒ–ç»“æœï¼š4 è¡Œ Ã— 6 å­—
- ä¾èµ–æ–‡ä»¶ï¼špoetry_vocabulary.txt, lstm_poetry_model.keras

%pip install gradio
"""
import os
import random
import numpy as np
import gradio as gr

from keras import models

VOCAB_PATH = os.environ.get("POETRY_VOCAB_PATH", "poetry_vocabulary.txt")
MODEL_PATH = os.environ.get("POETRY_MODEL_PATH", "lstm_poetry_model.keras")
TOTAL_CHARS = 24  # æœ€ç»ˆæ€»å­—æ•°ï¼ŒåŒ…å«å‰ç½®æç¤ºè¯

# -------- è¯è¡¨åŠ è½½ --------
def load_vocab(path):
    if not os.path.exists(path):
        raise FileNotFoundError(f"æœªæ‰¾åˆ°è¯è¡¨ï¼š{path}")
    with open(path, "r", encoding="utf-8") as f:
        vocab = [line.rstrip("\n") for line in f]
    if not vocab:
        raise ValueError("è¯è¡¨ä¸ºç©º")
    token_to_id = {t: i for i, t in enumerate(vocab)}
    id_to_token = list(vocab)
    pad_like = ("", "[PAD]", "<PAD>", "[pad]", "<pad>")
    unk_like = ("[UNK]", "<UNK>", "[unk]", "<unk>")
    pad_id = next((i for i, t in enumerate(vocab) if t in pad_like), 0)
    unk_id = next((i for i, t in enumerate(vocab) if t in unk_like), 1 if len(vocab) > 1 else 0)
    return vocab, token_to_id, id_to_token, pad_id, unk_id

vocab, token_to_id, id_to_token, PAD_ID, UNK_ID = load_vocab(VOCAB_PATH)
VOCAB_SIZE = len(vocab)

def is_cjk(ch: str) -> bool:
    return len(ch) == 1 and "\u4e00" <= ch <= "\u9fff"

# å…è®¸é‡‡æ ·çš„å€™é€‰ï¼ˆä¼˜å…ˆä»…å•ä¸ªæ±‰å­—ï¼‰
ALLOWED_IDS = [i for i, t in enumerate(id_to_token) if is_cjk(t)]
if not ALLOWED_IDS:
    ALLOWED_IDS = [i for i in range(VOCAB_SIZE) if i not in (PAD_ID, UNK_ID)]

# -------- æ¨¡å‹åŠ è½½ --------
model = models.load_model(MODEL_PATH, compile=False)
try:
    out_dim = model.output_shape[-1]
    if out_dim != VOCAB_SIZE:
        raise ValueError(f"æ¨¡å‹è¾“å‡ºç»´åº¦({out_dim})ä¸è¯è¡¨å¤§å°({VOCAB_SIZE})ä¸ä¸€è‡´")
except Exception:
    pass  # æŸäº›æ¨¡å¼ä¸‹æ‹¿ä¸åˆ° output_shapeï¼Œå¿½ç•¥

# -------- ç¼–è§£ç  --------
def text_to_ids(text: str):
    return [token_to_id.get(ch, UNK_ID) for ch in list(text or "")]

# -------- é‡‡æ ·ï¼ˆä»…æ¸©åº¦ï¼‰--------
def sample_id_from_probs(probs: np.ndarray, temperature: float) -> int:
    probs = np.asarray(probs, dtype="float64")
    mask = np.zeros_like(probs, dtype=bool)
    mask[ALLOWED_IDS] = True
    probs = np.where(mask, np.maximum(probs, 0.0), 0.0)
    s = probs.sum()
    if s <= 0:
        return int(random.choice(ALLOWED_IDS))
    probs = probs / s

    if temperature <= 0:
        return int(np.argmax(probs))

    logits = np.log(probs + 1e-9) / float(temperature)
    logits -= np.max(logits)
    p = np.exp(logits)
    ps = p.sum()
    if ps <= 0:
        return int(random.choice(ALLOWED_IDS))
    p /= ps
    return int(np.random.choice(len(p), p=p))

# -------- ç”Ÿæˆï¼ˆæ€»è®¡ 24 å­—ï¼ŒåŒ…å«å‰ç½®æç¤ºè¯ï¼‰--------
def generate_total_24(seed_text: str, temperature: float) -> str:
    seed_text = (seed_text or "").strip()
    if not seed_text:
        return "âš ï¸ è¯·è‡³å°‘è¾“å…¥ä¸€ä¸ªèµ·å§‹å­—ã€‚"

    ids = text_to_ids(seed_text)

    # å…ˆæŠŠå‰ç½®æç¤ºè¯é‡Œçš„æ±‰å­—æ”¾å…¥å±•ç¤ºåºåˆ—
    displayed_chars = [ch for ch in seed_text if is_cjk(ch)]
    displayed_chars = displayed_chars[:TOTAL_CHARS]  # è¿‡é•¿åˆ™æˆªæ–­ç›´æ¥è¿”å›
    if len(displayed_chars) >= TOTAL_CHARS:
        # ç›´æ¥æ ¼å¼åŒ–è¾“å‡º
        lines = ["".join(displayed_chars[i:i+6]) for i in range(0, TOTAL_CHARS, 6)]
        return "\n".join(lines)

    need = TOTAL_CHARS - len(displayed_chars)

    safety_steps = 2048
    while need > 0 and safety_steps > 0:
        x = np.array([ids], dtype="int32")
        preds = model.predict(x, verbose=0)
        next_probs = preds[0, -1]
        nid = sample_id_from_probs(next_probs, temperature)
        ids.append(nid)
        tok = id_to_token[nid]
        if is_cjk(tok):
            displayed_chars.append(tok)
            need -= 1
        safety_steps -= 1

    # æ ¼å¼åŒ–ä¸º 4Ã—6
    if len(displayed_chars) < TOTAL_CHARS:
        # æç«¯æƒ…å†µä¸‹è¡¥ç©ºæ ¼ä¿æŒæ’ç‰ˆæ•´é½ï¼ˆä¸€èˆ¬ä¸ä¼šè§¦å‘ï¼‰
        displayed_chars += ["ã€€"] * (TOTAL_CHARS - len(displayed_chars))
    lines = ["".join(displayed_chars[i:i+6]) for i in range(0, TOTAL_CHARS, 6)]
    return "\n".join(lines)

# -------- Gradio UI --------
DESC = "# äº”è¨€ç»å¥ç”Ÿæˆ\nè¯·è¾“å…¥**è‡³å°‘ 1 ä¸ªèµ·å§‹å­—**ï¼Œæ€»å­—æ•°å›ºå®š 24ï¼ˆåŒ…å«èµ·å§‹å­—ï¼‰ï¼Œä»…å±•ç¤º 4Ã—6 æ’ç‰ˆç»“æœã€‚"

with gr.Blocks(title="äº”è¨€ç»å¥ç”Ÿæˆ") as demo:
    gr.Markdown(DESC)
    with gr.Row():
        seed = gr.Textbox(label="å‰ç½®æç¤ºè¯ï¼ˆè‡³å°‘ 1 ä¸ªå­—ï¼‰", placeholder="ä¾‹å¦‚ï¼šæµ·å¤–", lines=1)
    with gr.Row():
        temp = gr.Slider(0, 2.0, value=0.5, step=0.05, label="æ¸©åº¦ï¼ˆ0=è´ªå¿ƒï¼‰")
    btn = gr.Button("ğŸ“ ç”Ÿæˆ")
    output = gr.Textbox(label="ç”Ÿæˆç»“æœ", lines=6)

    btn.click(fn=generate_total_24, inputs=[seed, temp], outputs=[output], api_name="generate")

    # é¡µè„šä¿¡æ¯
    with gr.Row():
        gr.Markdown(
            f"**æ¨¡å‹æ–‡ä»¶**ï¼š`{MODEL_PATH}` ï½œ **è¯è¡¨**ï¼š`{VOCAB_PATH}` ï½œ **è¯è¡¨å¤§å°**ï¼š{VOCAB_SIZE}"
        )

if __name__ == "__main__":
    port = int(os.environ.get("GRADIO_PORT", "7860"))
    demo.launch(server_name="0.0.0.0", server_port=port, share=False)
